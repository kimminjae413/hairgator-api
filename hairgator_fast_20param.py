#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ v8.0 - 15ì´ˆ ì´ë‚´ ì‘ë‹µ ìµœì í™”
20íŒŒë¼ë¯¸í„° ê¸°ë°˜ ê³ ì† ì „ë¬¸ê°€ ë‹µë³€ ì‹œìŠ¤í…œ

Updated: 2025-01-25
Version: 8.0 - Fast 20 Parameters
Features:
- 20íŒŒë¼ë¯¸í„°ë¡œ ì¶•ì†Œí•˜ì—¬ 15ì´ˆ ì´ë‚´ ì‘ë‹µ
- OpenAI API íƒ€ì„ì•„ì›ƒ 15ì´ˆë¡œ ìµœì í™”
- ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
- ë Œë” ë°°í¬ ìµœì í™”
- ì˜¤ë¥˜ ì—†ëŠ” ì™„ì „í•œ ì‹¤í–‰ ê°€ëŠ¥ ì½”ë“œ
"""

import os
import sys
import json
import uuid
import base64
import asyncio
import pandas as pd
import locale
from datetime import datetime
from typing import Dict, List, Any, Optional

# UTF-8 ì¸ì½”ë”© ê°•ì œ ì„¤ì •
if sys.platform.startswith('win'):
    try:
        locale.setlocale(locale.LC_ALL, 'ko_KR.UTF-8')
    except:
        try:
            locale.setlocale(locale.LC_ALL, 'Korean_Korea.UTF-8')
        except:
            pass

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
try:
    from dotenv import load_dotenv
    load_dotenv(dotenv_path=".env", override=True)
except ImportError:
    print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì„¸ìš”.")

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë° ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_key_here")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY", "your_anthropic_key_here") 
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")

print(f"ğŸ”‘ Environment Variables Check:")
print(f"   OPENAI_API_KEY: {'âœ… Set' if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here' else 'âŒ Not Set'}")
print(f"   ANTHROPIC_API_KEY: {'âœ… Set' if ANTHROPIC_API_KEY and ANTHROPIC_API_KEY != 'your_anthropic_key_here' else 'âŒ Not Set'}")
print(f"   REDIS_URL: {REDIS_URL}")

from fastapi import FastAPI, HTTPException, File, UploadFile, Form, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, field_validator
import requests
import re

# OpenAI ë° Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    import openai
    if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here':
        openai.api_key = OPENAI_API_KEY
        print("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ")
    else:
        print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
except ImportError:
    print("âŒ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    openai = None

# Anthropic ì™„ì „ ë¹„í™œì„±í™” (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´)
anthropic_client = None
print("âš ï¸ Anthropic ë¹„í™œì„±í™” - OpenAIë§Œ ì‚¬ìš©ìœ¼ë¡œ ì†ë„ ìµœì í™”")

# Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    import redis
    redis_client = redis.from_url(REDIS_URL, decode_responses=True)
    redis_client.ping()
    redis_available = True
    print("âœ… Redis ì—°ê²° ì„±ê³µ")
except Exception as e:
    redis_client = None
    redis_available = False
    print(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨ (ë©”ëª¨ë¦¬ ëª¨ë“œ ì‚¬ìš©): {e}")

# PIL ì´ë¯¸ì§€ ì²˜ë¦¬ ì´ˆê¸°í™”
try:
    from PIL import Image
    import io
    print("âœ… PIL ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âŒ PIL íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
    Image = None
    io = None

# =============================================================================
# í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì»¨í…ìŠ¤íŠ¸ ê°ì§€ ì‹œìŠ¤í…œ
# =============================================================================

class HairgatorProContextSystem:
    """í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì»¨í…ìŠ¤íŠ¸ ê°ì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # í—¤ì–´ë””ìì´ë„ˆ ì „ë¬¸ í‚¤ì›Œë“œ (ê°„ì†Œí™”)
        self.professional_hair_keywords = [
            # ê¸°ë³¸ í—¤ì–´ í‚¤ì›Œë“œë“¤
            'í—¤ì–´', 'ë¨¸ë¦¬', 'ëª¨ë°œ', 'ì»·', 'ìë¥´', 'ìŠ¤íƒ€ì¼', 'íŒ', 'ì—¼ìƒ‰',
            'hair', 'cut', 'style', 'ë‹¨ë°œ', 'ë¡±', 'ì‡¼íŠ¸', 'ë¯¸ë””ì›€',
            'ë³¼ë¥¨', 'ë ˆì´ì–´', 'ì•ë¨¸ë¦¬', 'ë’·ë¨¸ë¦¬', 'ì˜†ë¨¸ë¦¬', 'ê°€ë¥´ë§ˆ',
            'ê³±ìŠ¬', 'ì§ëª¨', 'ì›¨ì´ë¸Œ', 'ë“œë¼ì´', 'ë¸”ë¡œìš°', 'ìŠ¤íƒ€ì¼ë§',
            
            # ì „ë¬¸ ìš©ì–´ (ê°„ì†Œí™”)
            'í¬ë®¬ëŸ¬', 'ì„¹ì…˜', 'ì—˜ë¦¬ë² ì´ì…˜', 'ë””ë ‰ì…˜', 'ë¦¬í”„íŒ…', 'ë””ìì¸ë¼ì¸',
            'formula', 'section', 'elevation', 'direction', 'lifting', 'design line',
            'ë””ìŠ¤íŠ¸ë¦¬ë·°ì…˜', 'ì›¨ì´íŠ¸í”Œë¡œìš°', 'ì•„ì›ƒë¼ì¸',
            'distribution', 'weight flow', 'outline'
        ]
        
        # í—¤ì–´ë””ìì´ë„ˆ ì§ˆë¬¸ íŒ¨í„´ (ê°„ì†Œí™”)
        self.professional_question_patterns = [
            'ë ˆì‹œí”¼', 'recipe', 'ì‹œìˆ ë²•', 'ê¸°ë²•', 'technique',
            'ì–´ë–»ê²Œ ì»¤íŠ¸', 'ì–´ë–»ê²Œ ìë¥´', 'ì»¤íŒ…ë°©ë²•', 'cutting method',
            'íŒŒë¼ë¯¸í„°', 'parameter', 'ê°ë„', 'angle', 'ì„¹ì…˜', 'section',
            'ëª‡ë„ë¡œ', 'ì–´ë–¤ ê°ë„', 'ì–´ë–¤ ì„¹ì…˜', 'ì–´ë–¤ ë°©í–¥',
            'ë³¼ë¥¨ ì‚´ë¦¬', 'ë¬´ê²Œê° ì¡°ì ˆ', 'ê¸¸ì´ ì¡°ì ˆ', 'ë ˆì´ì–´', 'layer',
            'ì´ë¯¸ì§€ ë¶„ì„', 'ì‚¬ì§„ ë¶„ì„', 'í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„', 'ìŠ¤íƒ€ì¼ í•´ì„'
        ]
    
    def is_professional_hair_question(self, query: str) -> bool:
        """í—¤ì–´ë””ìì´ë„ˆ ì „ë¬¸ ì§ˆë¬¸ì¸ì§€ íŒë‹¨ - ëª¨ë“  í—¤ì–´ ê´€ë ¨ ì§ˆë¬¸ì„ ì „ë¬¸ê°€ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬"""
        if not query or not isinstance(query, str):
            return False
            
        query_lower = query.lower()
        
        # ì „ë¬¸ í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword in self.professional_hair_keywords:
            if keyword.lower() in query_lower:
                return True
        
        # ì „ë¬¸ ì§ˆë¬¸ íŒ¨í„´ ë§¤ì¹­
        for pattern in self.professional_question_patterns:
            if pattern.lower() in query_lower:
                return True
        
        return False

# =============================================================================
# ë°ì´í„° ëª¨ë¸
# =============================================================================

class ChatMessage(BaseModel):
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í• ")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")
    timestamp: Optional[str] = Field(None, description="íƒ€ì„ìŠ¤íƒ¬í”„")
    
    class Config:
        validate_assignment = True
        str_strip_whitespace = True

class ChatRequest(BaseModel):
    user_id: str = Field(..., description="ì‚¬ìš©ì ID", min_length=1, max_length=100)
    message: str = Field("", description="ë©”ì‹œì§€ ë‚´ìš© (ì´ë¯¸ì§€ë§Œ ì…ë ¥ ì‹œ ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)", max_length=2000)
    conversation_id: Optional[str] = Field(None, description="ëŒ€í™” ID")
    image_url: Optional[str] = Field(None, description="ì´ë¯¸ì§€ URL")
    use_rag: Optional[bool] = Field(True, description="RAG ì‚¬ìš© ì—¬ë¶€")
    
    @field_validator('message')
    @classmethod
    def validate_message(cls, v, info):
        # ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (ì´ë¯¸ì§€ë§Œ ì…ë ¥ë„ í—ˆìš©)
        if not v:
            return ""
        
        v = str(v).strip()
        v = v.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
        v = ' '.join(v.split())
        return v
    
    @field_validator('user_id')
    @classmethod
    def validate_user_id(cls, v):
        if not v or not v.strip():
            raise ValueError('ì‚¬ìš©ì IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤')
        return v.strip()

class ChatResponse(BaseModel):
    conversation_id: str = Field(..., description="ëŒ€í™” ID")
    message: str = Field(..., description="ì‘ë‹µ ë©”ì‹œì§€")
    timestamp: str = Field(..., description="ì‘ë‹µ ì‹œê°„")
    message_type: str = Field(default="chat", description="ë©”ì‹œì§€ íƒ€ì…")
    additional_data: Optional[Dict] = Field(None, description="ì¶”ê°€ ë°ì´í„°")

# =============================================================================
# OpenAI ëª¨ë¸ í™•ì¸ ë° ì„ íƒ
# =============================================================================

async def get_available_openai_model():
    """ì‚¬ìš© ê°€ëŠ¥í•œ OpenAI ëª¨ë¸ í™•ì¸ ë° ì„ íƒ"""
    if not OPENAI_API_KEY or OPENAI_API_KEY == 'your_openai_key_here' or not openai:
        return None
    
    preferred_models = [
        "gpt-4-turbo",
        "gpt-4",
        "gpt-3.5-turbo-16k",
        "gpt-3.5-turbo"
    ]
    
    try:
        models_response = await openai.Model.alist()
        available_models = [model.id for model in models_response.data]
        
        for model in preferred_models:
            if model in available_models:
                print(f"âœ… ì„ íƒëœ OpenAI ëª¨ë¸: {model}")
                return model
        
        print("âš ï¸ ì„ í˜¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, gpt-3.5-turbo ì‚¬ìš©")
        return "gpt-3.5-turbo"
        
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}, gpt-3.5-turbo ì‚¬ìš©")
        return "gpt-3.5-turbo"

SELECTED_MODEL = None

# =============================================================================
# RAG ë°ì´í„°ë² ì´ìŠ¤ í´ë˜ìŠ¤ (ê°„ì†Œí™”)
# =============================================================================

class HairgatorRAGDatabase:
    def __init__(self):
        self.styles_data = []
        self.parameters_data = {}
        self.conversation_data = {}
        self.load_excel_data()
    
    def load_excel_data(self):
        """ì—‘ì…€ ë°ì´í„° ë¡œë“œ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            print("ğŸ“š RAG ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì¤‘...")
            
            excel_file = 'í—¤ì–´ê²Œì´í„° ìŠ¤íƒ€ì¼ ë©”ë‰´ í…ìŠ¤íŠ¸_women_rag_v2.xlsx'
            if not os.path.exists(excel_file):
                print(f"âš ï¸ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {excel_file}")
                self.setup_default_data()
                return
            
            # ì—‘ì…€ íŒŒì¼ ì½ê¸°
            try:
                df_styles = pd.read_excel(excel_file, 
                            sheet_name='Style menu_Female',
                            header=7)
                print(f"ğŸ“Š ì—‘ì…€ ì»¬ëŸ¼ë“¤: {list(df_styles.columns)}")
            except Exception as e:
                print(f"âš ï¸ header=7ë¡œ ì½ê¸° ì‹¤íŒ¨: {e}")
                df_styles = pd.read_excel(excel_file, 
                            sheet_name='Style menu_Female',
                            header=0)
                print(f"ğŸ“Š ì—‘ì…€ ì»¬ëŸ¼ë“¤: {list(df_styles.columns)}")
            
            print(f"ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(df_styles)}")
            
            # ë°ì´í„° ì²˜ë¦¬
            loaded_count = 0
            for idx, row in df_styles.iterrows():
                model_no = row.get('St model no.') or row.get('model_no') or row.get('St model no') 
                
                if pd.notna(model_no) and str(model_no).strip():
                    style_data = {
                        'model_no': str(model_no).strip(),
                        'introduction_kor': str(row.get('Style Introduction(KOR)', row.get('introduction_kor', ''))).strip(),
                        'management_kor': str(row.get('Management(KOR)', row.get('management_kor', ''))).strip(),
                        'image_analysis_kor': str(row.get('Image Analysis(KOR)', row.get('image_analysis_kor', ''))).strip(),
                        'subtitle': str(row.get('subtitle', '')).strip(),
                        'formula_42': str(row.get('42fomular', row.get('formula_42', ''))).strip(),
                        'session_meaning': str(row.get('ì„¸ì…˜ì „í™˜ì˜ë¯¸', row.get('session_meaning', ''))).strip(),
                        'ground_truth': str(row.get('groundtruce', row.get('ground_truth', ''))).strip(),
                        'image_url': str(row.get('ì´ë¯¸ì§€ URL', row.get('image_url', ''))).strip()
                    }
                    
                    # ë¹ˆ ë¬¸ìì—´ê³¼ 'nan' ì²˜ë¦¬
                    for key, value in style_data.items():
                        if value in ['nan', 'None', '']:
                            style_data[key] = ''
                    
                    self.styles_data.append(style_data)
                    loaded_count += 1
                    
                    if loaded_count <= 3:
                        print(f"ğŸ“ [{loaded_count}] {style_data['model_no']}: {style_data['introduction_kor'][:30]}...")
            
            print(f"âœ… RAG ìŠ¤íƒ€ì¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {loaded_count}ê°œ")
            
        except Exception as e:
            print(f"âŒ ì—‘ì…€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            self.setup_default_data()
    
    def setup_default_data(self):
        """ê¸°ë³¸ ë°ì´í„° ì„¤ì • - ë‹¨ë°œ ê´€ë ¨ ë°ì´í„° í¬í•¨"""
        print("ğŸ”§ ê¸°ë³¸ ë°ì´í„° ì„¤ì • ì¤‘...")
        self.styles_data = [
            {
                'model_no': 'FAL0001',
                'introduction_kor': 'í´ë˜ì‹ ë‹¨ë°œ ë°¥ì»·',
                'ground_truth': '''[í¬ë®¬ëŸ¬ 1: ìˆ˜í‰ì„¹ì…˜ 0ë„ ìŠ¤í…Œì´ì…”ë„ˆë¦¬ë¼ì¸] â€“ ë‹¨ë°œ ê¸°ë³¸ êµ¬ì¡°
â†’ Section: Horizontal + ìˆ˜í‰ ì„¹ì…˜ìœ¼ë¡œ ê¹”ë”í•œ ë‹¨ë°œ ë¼ì¸
â†’ Elevation: L0 (0Â°) + 0ë„ ê°ë„ë¡œ ë¬´ê²Œê° ìˆëŠ” ë°¥ì»·
â†’ Cut Form: O (One-length) + ì›ë­ìŠ¤ë¡œ ê· ì¼í•œ ë‹¨ë°œ ê¸¸ì´
â†’ Weight Flow: Balanced + ê· í˜•ì¡íŒ ë¬´ê²Œê° ë¶„í¬''',
                'subtitle': 'ë‹¨ë°œ ë°¥ì»· ê¸°ë³¸ ë ˆì‹œí”¼',
                'formula_42': 'Horizontal Section, L0 Elevation, One-length'
            },
            {
                'model_no': 'FAL0002',
                'introduction_kor': 'ë‹¨ë°œë¨¸ë¦¬ ë ˆì´ì–´ë“œ ìŠ¤íƒ€ì¼', 
                'ground_truth': '''[í¬ë®¬ëŸ¬ 1: ìˆ˜ì§ì„¹ì…˜ 45ë„ ëª¨ë°”ì¼ë¼ì¸] â€“ ë‹¨ë°œ ë ˆì´ì–´ë§
â†’ Section: Vertical + ìˆ˜ì§ ì„¹ì…˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë ˆì´ì–´ ì—°ê²°
â†’ Elevation: L2 (45Â°) + 45ë„ ê°ë„ë¡œ ì ë‹¹í•œ ë³¼ë¥¨ ìƒì„±
â†’ Cut Form: L (Layer) + ë ˆì´ì–´ êµ¬ì¡°ë¡œ ì›€ì§ì„ê³¼ ê²½ëŸ‰ê°
â†’ Structure Layer: Medium Layer + ì¤‘ê°„ ë ˆì´ì–´ë¡œ ë³¼ë¥¨ê³¼ ê¸¸ì´ê° ì ˆì¶©''',
                'subtitle': 'ë‹¨ë°œì— ë ˆì´ì–´ë¥¼ ì ìš©í•œ ë™ì  ìŠ¤íƒ€ì¼',
                'formula_42': 'Vertical Section, L2 Elevation, Layer Cut'
            },
            {
                'model_no': 'FAL0003',
                'introduction_kor': 'ë¯¸ë””ì›€ ë ˆì´ì–´ ìŠ¤íƒ€ì¼',
                'ground_truth': '''[í¬ë®¬ëŸ¬ 1: ìˆ˜ì§ì„¹ì…˜ 45ë„ ëª¨ë°”ì¼ë¼ì¸] â€“ ë¯¸ë””ì›€ ë ˆì´ì–´
â†’ Section: Vertical + ìì—°ìŠ¤ëŸ¬ìš´ ë ˆì´ì–´ ì—°ê²°
â†’ Elevation: L2 (45Â°) + ì ë‹¹í•œ ë³¼ë¥¨ ìƒì„±
â†’ Cut Form: L (Layer) + ì›€ì§ì„ê³¼ ê²½ëŸ‰ê°
â†’ Weight Flow: Balanced + ê· í˜•ì¡íŒ ë¬´ê²Œê°''',
                'subtitle': 'ë¯¸ë””ì›€ ê¸¸ì´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë ˆì´ì–´',
                'formula_42': 'Vertical Section, L2 Elevation, Mobile Line'
            }
        ]
        print(f"âœ… ê¸°ë³¸ ë°ì´í„° ì„¤ì • ì™„ë£Œ: {len(self.styles_data)}ê°œ")
    
    def search_similar_styles(self, query: str, limit: int = 3) -> List[Dict]:
        """ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ê²€ìƒ‰"""
        results = []
        query_lower = query.lower()
        
        print(f"ğŸ” RAG ê²€ìƒ‰ ì‹œì‘ - ì¿¼ë¦¬: '{query}', ë°ì´í„° ìˆ˜: {len(self.styles_data)}")
        
        # í‚¤ì›Œë“œ í™•ì¥
        search_keywords = [query_lower]
        
        if 'ë‹¨ë°œ' in query_lower or 'bob' in query_lower:
            search_keywords.extend(['ë‹¨ë°œ', 'bob', 'ë°¥', 'ì‡¼íŠ¸', 'short', 'í„±ì„ '])
        
        if 'ë ˆì‹œí”¼' in query_lower or 'recipe' in query_lower:
            search_keywords.extend(['ì»¤íŠ¸', 'cut', 'ì‹œìˆ ', 'ê¸°ë²•'])
        
        if 'ë¡±' in query_lower or 'long' in query_lower:
            search_keywords.extend(['ë¡±', 'long', 'ê¸´ë¨¸ë¦¬', 'ì–´ê¹¨ì•„ë˜'])
            
        if 'ë¯¸ë””ì›€' in query_lower or 'medium' in query_lower:
            search_keywords.extend(['ë¯¸ë””ì›€', 'medium', 'ì¤‘ê°„ê¸¸ì´', 'ì–´ê¹¨ì„ '])
        
        for i, style in enumerate(self.styles_data):
            score = 0
            matched_fields = []
            
            # ëª¨ë“  í…ìŠ¤íŠ¸ í•„ë“œì—ì„œ ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)
            search_fields = {
                'introduction_kor': 5,
                'subtitle': 3,
                'ground_truth': 3,
                'image_analysis_kor': 2,
                'formula_42': 2,
                'session_meaning': 1,
                'management_kor': 1
            }
            
            for field_name, weight in search_fields.items():
                field_value = str(style.get(field_name, '')).lower()
                
                if field_value and field_value != 'nan':
                    for keyword in search_keywords:
                        if keyword in field_value:
                            score += weight
                            matched_fields.append(f"{field_name}:{keyword}")
            
            if score > 0:
                results.append({
                    'style': style,
                    'score': score,
                    'matched_fields': matched_fields
                })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x['score'], reverse=True)
        found_styles = [r['style'] for r in results[:limit]]
        
        print(f"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ - ì°¾ì€ ìŠ¤íƒ€ì¼: {len(found_styles)}ê°œ")
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìŠ¤íƒ€ì¼ ë°˜í™˜
        if not found_styles and self.styles_data:
            found_styles = self.styles_data[:3]
        
        return found_styles

# =============================================================================
# ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ - 20íŒŒë¼ë¯¸í„° ê³ ì† ë²„ì „
# =============================================================================

async def generate_fast_20param_response(messages: List[ChatMessage], claude_analysis: str = None, rag_context: str = None) -> str:
    """20íŒŒë¼ë¯¸í„° ê¸°ë°˜ ê³ ì† ì „ë¬¸ê°€ ì‘ë‹µ ìƒì„± - 15ì´ˆ ì´ë‚´ ìµœì í™”"""
    
    if not OPENAI_API_KEY or OPENAI_API_KEY == 'your_openai_key_here' or not openai:
        return generate_fallback_20param_response("API ì„¤ì • í•„ìš”")
    
    global SELECTED_MODEL
    if SELECTED_MODEL is None:
        SELECTED_MODEL = await get_available_openai_model()
        if SELECTED_MODEL is None:
            return generate_fallback_20param_response("ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€")
    
    try:
        last_message = messages[-1].content if messages else "í—¤ì–´ìŠ¤íƒ€ì¼ ê¸°ìˆ  ë¶„ì„ ìš”ì²­"
        
        print(f"âš¡ 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì‹œì‘: {last_message[:50]}...")
        
        # ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´)
        fast_prompt = f"""ë‹¹ì‹ ì€ í—¤ì–´ê²Œì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸: {last_message}

ë‹¤ìŒ 20ê°œ í•µì‹¬ íŒŒë¼ë¯¸í„°ë¡œ ê°„ë‹¨í•˜ê³  ì •í™•í•œ í—¤ì–´ ë ˆì‹œí”¼ë¥¼ ì œê³µí•˜ì„¸ìš”:

**í•µì‹¬ 20íŒŒë¼ë¯¸í„°:**
1. Section (Horizontal/Vertical/Diagonal)
2. Elevation (L0-L8) 
3. Cut Form (O/G/L)
4. Cut Shape (Square/Round/Triangular)
5. Weight Flow (Balanced/Forward/Backward/Side Weighted)
6. Design Line (Stationary/Mobile/Combination)
7. Length (A/B/C/D/E)
8. Cut Method (Blunt/Point/Slide/Twist Cut)
9. Styling Direction (Forward/Backward/Side/Natural Fall)
10. Finish Look (Blow Dry/Air Dry/Heat Set)
11. Texture Finish (Soft Gloss/Natural/Matte)
12. Design Emphasis (Volume/Shape/Curl/Length Emphasis)
13. Natural Parting (Center/Side/No Parting)
14. Styling Product (None/Light/Medium/Strong Hold)
15. Fringe Type (No Fringe/Full/Side/Curtain Fringe)
16. Structure Layer (No Layer/Long/Medium/Short Layer)
17. Volume Zone (Low/Medium/High)
18. Interior Design (Connected/Disconnected)
19. Distribution (Natural Fall/Shifted/Perpendicular)
20. Cut Categories (Women's/Men's/Unisex Cut)

**ì‘ë‹µ í˜•ì‹:**
ğŸ¯ 20íŒŒë¼ë¯¸í„° í—¤ì–´ ë ˆì‹œí”¼

[í¬ë®¬ëŸ¬ 1: ì„¹ì…˜íƒ€ì… ê°ë„ ë””ìì¸ë¼ì¸] â€“ ìŠ¤íƒ€ì¼ëª…

**í•µì‹¬ íŒŒë¼ë¯¸í„°:**
â†’ Section: [ê°’] + [ê°„ë‹¨ ì„¤ëª…]
â†’ Elevation: [ê°’] + [ê°„ë‹¨ ì„¤ëª…]
â†’ Cut Form: [ê°’] + [ê°„ë‹¨ ì„¤ëª…]
(ë‚˜ë¨¸ì§€ 17ê°œ íŒŒë¼ë¯¸í„°)

**ì»¤íŒ… ìˆœì„œ:**
1. [ë‹¨ê³„1]
2. [ë‹¨ê³„2] 
3. [ë‹¨ê³„3]
4. [ë‹¨ê³„4]

**ëª¨ë°œ íƒ€ì…ë³„ í¬ì¸íŠ¸:**
* ì§ëª¨: [í¬ì¸íŠ¸]
* ê³±ìŠ¬ëª¨: [í¬ì¸íŠ¸]
* ê°€ëŠ”ëª¨ë°œ: [í¬ì¸íŠ¸]
* êµµì€ëª¨ë°œ: [í¬ì¸íŠ¸]

**ê´€ë¦¬ë²•:**
* [ê´€ë¦¬ í¬ì¸íŠ¸ 1]
* [ê´€ë¦¬ í¬ì¸íŠ¸ 2]
* [ê´€ë¦¬ í¬ì¸íŠ¸ 3]

ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. JSONì´ë‚˜ ì½”ë“œë¸”ë¡ ì‚¬ìš© ê¸ˆì§€."""
        
        if rag_context:
            fast_prompt += f"\n\nì°¸ê³  ë°ì´í„°:\n{rag_context[:500]}"
        
        print(f"ğŸ”¬ ê³ ì† ë¶„ì„ ëª¨ë¸: {SELECTED_MODEL}")
        
        # ìµœëŒ€ í† í° ì¶•ì†Œ (ë¹ ë¥¸ ì²˜ë¦¬)
        max_tokens = 1500  # í¬ê²Œ ì¶•ì†Œ
        
        # GPT í˜¸ì¶œ (15ì´ˆ íƒ€ì„ì•„ì›ƒ)
        response = await asyncio.wait_for(
            openai.ChatCompletion.acreate(
                model=SELECTED_MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": fast_prompt
                    },
                    {
                        "role": "user", 
                        "content": f"20íŒŒë¼ë¯¸í„°ë¡œ ê°„ë‹¨í•œ í—¤ì–´ ë ˆì‹œí”¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”: {last_message}"
                    }
                ],
                max_tokens=max_tokens,
                temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ê²Œ
                top_p=0.9,
                frequency_penalty=0.1,
                presence_penalty=0.1
            ),
            timeout=15.0  # 15ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        
        result = response.choices[0].message.content
        result = clean_gpt_response(result)
        
        print(f"âœ… 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì™„ë£Œ (ê¸¸ì´: {len(result)})")
        return result
        
    except asyncio.TimeoutError:
        print(f"â° 20íŒŒë¼ë¯¸í„° ë¶„ì„ íƒ€ì„ì•„ì›ƒ (15ì´ˆ)")
        return f"""âš¡ 20íŒŒë¼ë¯¸í„° í—¤ì–´ ë ˆì‹œí”¼

**íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•œ ê¸°ë³¸ ë¶„ì„:**

{last_message[:100]}ì— ëŒ€í•œ ë¶„ì„ì´ íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ¯ ê¸°ë³¸ 20íŒŒë¼ë¯¸í„° ë ˆì‹œí”¼

[í¬ë®¬ëŸ¬ 1: ìˆ˜ì§ì„¹ì…˜ 45ë„ ëª¨ë°”ì¼ë¼ì¸] â€“ ë¯¸ë””ì›€ ë ˆì´ì–´

**í•µì‹¬ íŒŒë¼ë¯¸í„°:**
â†’ Section: Vertical + ìì—°ìŠ¤ëŸ¬ìš´ ë ˆì´ì–´ ì—°ê²°
â†’ Elevation: L2 (45Â°) + ì ë‹¹í•œ ë³¼ë¥¨ ìƒì„±
â†’ Cut Form: L (Layer) + ì›€ì§ì„ê³¼ ê²½ëŸ‰ê°
â†’ Cut Shape: Round + ë¶€ë“œëŸ¬ìš´ í˜•íƒœ
â†’ Weight Flow: Balanced + ê· í˜•ì¡íŒ ë¬´ê²Œê°
â†’ Design Line: Mobile + ì›€ì§ì´ëŠ” ê°€ì´ë“œë¼ì¸
â†’ Length: D + ì–´ê¹¨ì„  ê·¼ì²˜ ê¸¸ì´
â†’ Cut Method: Point Cut + ìì—°ìŠ¤ëŸ¬ìš´ ëì²˜ë¦¬
â†’ Styling Direction: Forward + ì•ìª½ ë°©í–¥ ìŠ¤íƒ€ì¼ë§
â†’ Finish Look: Blow Dry + ë¸”ë¡œìš° ë“œë¼ì´ ë§ˆë¬´ë¦¬
â†’ Texture Finish: Natural + ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆê°
â†’ Design Emphasis: Shape Emphasis + í˜•íƒœ ê°•ì¡°
â†’ Natural Parting: Side + ì˜†ê°€ë¥´ë§ˆ
â†’ Styling Product: Light Hold + ê°€ë²¼ìš´ í™€ë“œ
â†’ Fringe Type: No Fringe + ì•ë¨¸ë¦¬ ì—†ìŒ
â†’ Structure Layer: Medium Layer + ì¤‘ê°„ ë ˆì´ì–´
â†’ Volume Zone: Medium + ì¤‘ê°„ ë³¼ë¥¨
â†’ Interior Design: Connected + ì—°ê²°ëœ êµ¬ì¡°
â†’ Distribution: Natural Fall + ìì—° ë¶„ë°°
â†’ Cut Categories: Women's Cut + ì—¬ì„± ì»¤íŠ¸

ë‹¤ì‹œ ì‹œë„í•˜ì‹œë©´ ì™„ì „í•œ ë¶„ì„ì„ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"""
        
    except Exception as e:
        print(f"âŒ 20íŒŒë¼ë¯¸í„° ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}")
        return generate_fallback_20param_response(last_message)

def clean_gpt_response(response_text: str) -> str:
    """GPT ì‘ë‹µì—ì„œ JSON ë¸”ë¡ ì™„ì „ ì œê±° ë° íŒŒë¼ë¯¸í„° ê°’ ê²€ì¦"""
    try:
        # JSON ë¸”ë¡ ì œê±°
        json_patterns = [
            r'```json.*?```',
            r'```.*?```',
            r'`[^`]*`',
            r'\{[^{}]*"[^"]*"[^{}]*\}',
            r'\[[^\[\]]*"[^"]*"[^\[\]]*\]'
        ]
        
        cleaned_text = response_text
        for pattern in json_patterns:
            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.DOTALL)
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_text = re.sub(r'\n\s*\n', '\n\n', cleaned_text)
        cleaned_text = re.sub(r' {2,}', ' ', cleaned_text)
        cleaned_text = cleaned_text.strip()
        
        return cleaned_text if cleaned_text else response_text
        
    except Exception as e:
        print(f"âš ï¸ ì‘ë‹µ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return response_text

def generate_fallback_20param_response(user_message: str) -> str:
    """20íŒŒë¼ë¯¸í„°ìš© ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
    return f"""âš¡ 20íŒŒë¼ë¯¸í„° í—¤ì–´ ë ˆì‹œí”¼

**ì „ë¬¸ê°€ ì§ˆë¬¸ ë¶„ì„**: {user_message[:100]}...

ğŸ¯ [í¬ë®¬ëŸ¬ 1: ìˆ˜ì§ì„¹ì…˜ 45ë„ ëª¨ë°”ì¼ë¼ì¸] â€“ ë¯¸ë””ì›€ ë ˆì´ì–´ ì„¤ì •

**í•µì‹¬ 20íŒŒë¼ë¯¸í„°:**
â†’ Section: Vertical + ìì—°ìŠ¤ëŸ¬ìš´ ë ˆì´ì–´ ì—°ê²°ì„ ìœ„í•œ ìˆ˜ì§ ë¶„í• 
â†’ Elevation: L2 (45Â°) + 45ë„ ê°ë„ë¡œ ì ë‹¹í•œ ë³¼ë¥¨ê³¼ ì›€ì§ì„ ìƒì„±
â†’ Cut Form: L (Layer) + ë ˆì´ì–´ êµ¬ì¡°ë¡œ ì›€ì§ì„ê³¼ ê²½ëŸ‰ê° ë™ì‹œ êµ¬í˜„
â†’ Cut Shape: Round + ë‘¥ê·¼ í˜•íƒœë¡œ ë¶€ë“œëŸ¬ìš´ ì—¬ì„±ìŠ¤ëŸ¬ìš´ ì¸ìƒ
â†’ Weight Flow: Balanced + ì „ì²´ì ìœ¼ë¡œ ê· í˜•ì¡íŒ ë¬´ê²Œê° ë¶„í¬
â†’ Design Line: Mobile + ì›€ì§ì´ëŠ” ê°€ì´ë“œë¼ì¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°ê°
â†’ Length: D + ì–´ê¹¨ì„  ê·¼ì²˜ ê¸¸ì´ë¡œ ì‹¤ìš©ì„±ê³¼ ì—¬ì„±ìŠ¤ëŸ¬ì›€ ë™ì‹œ ì¶”êµ¬
â†’ Cut Method: Point Cut + í¬ì¸íŠ¸ ì»·ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëì²˜ë¦¬
â†’ Styling Direction: Forward + ì•ìª½ ë°©í–¥ ìŠ¤íƒ€ì¼ë§ìœ¼ë¡œ ì–¼êµ´ì„ ê°ì‹¸ëŠ” íš¨ê³¼
â†’ Finish Look: Blow Dry + ë¸”ë¡œìš° ë“œë¼ì´ ë§ˆë¬´ë¦¬ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨ê³¼ ìœ¤ê¸°
â†’ Texture Finish: Natural + ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆê°ìœ¼ë¡œ ì¸ìœ„ì ì´ì§€ ì•Šì€ ë§ˆë¬´ë¦¬
â†’ Design Emphasis: Shape Emphasis + í˜•íƒœ ê°•ì¡°ë¡œ í—¤ì–´ìŠ¤íƒ€ì¼ì˜ ì‹¤ë£¨ì—£ì´ ì£¼ìš” í¬ì¸íŠ¸
â†’ Natural Parting: Side + ì˜†ê°€ë¥´ë§ˆë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ëŒ€ì¹­ ê· í˜•
â†’ Styling Product: Light Hold + ê°€ë²¼ìš´ í™€ë“œë ¥ ì œí’ˆìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì›€ì§ì„
â†’ Fringe Type: No Fringe + ì•ë¨¸ë¦¬ ì—†ëŠ” ìŠ¤íƒ€ì¼ë¡œ ì´ë§ˆë¥¼ ì‹œì›í•˜ê²Œ ë…¸ì¶œ
â†’ Structure Layer: Medium Layer + ì¤‘ê°„ ë ˆì´ì–´ êµ¬ì¡°ë¡œ ë³¼ë¥¨ê³¼ ê¸¸ì´ê°ì˜ ì ˆì¶©ì 
â†’ Volume Zone: Medium + ì¤‘ê°„ ì •ë„ì˜ ë³¼ë¥¨ì¡´ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë³¼ë¥¨
â†’ Interior Design: Connected + ë‚´ë¶€ê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ëœ êµ¬ì¡°
â†’ Distribution: Natural Fall + ìì—°ìŠ¤ëŸ¬ìš´ ë‚™í•˜ê°ìœ¼ë¡œ ë¬´ë¦¬ ì—†ëŠ” ìŠ¤íƒ€ì¼ë§
â†’ Cut Categories: Women's Cut + ì—¬ì„± ì»¤íŠ¸ì˜ ê¸°ë³¸ ì›ì¹™ ì ìš©

**ì»¤íŒ… ìˆœì„œ:**
1. **ì¤€ë¹„ë‹¨ê³„**: ëª¨ë°œ ìƒíƒœ ì²´í¬ ë° 7ê°œ êµ¬ì—­ ë¶„í• 
2. **1ì°¨ ì»¤íŒ…**: ë°± ì„¼í„°ì—ì„œ ê°€ì´ë“œë¼ì¸ ì„¤ì •, L2 45ë„ ìœ ì§€
3. **2ì°¨ ì •ë°€**: ì‚¬ì´ë“œì™€ ë°± ì˜ì—­ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°
4. **ë§ˆê° ì²˜ë¦¬**: Point Cutìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëì²˜ë¦¬

**ëª¨ë°œ íƒ€ì…ë³„ í¬ì¸íŠ¸:**
* **ì§ëª¨**: L3ë¡œ ê°ë„ ìƒí–¥ ì¡°ì •, ì›¨íŠ¸ ì»¤íŒ… ê¶Œì¥
* **ê³±ìŠ¬ëª¨**: ë“œë¼ì´ ì»¤íŒ…ìœ¼ë¡œ ì‹¤ì œ ì»¬ ìƒíƒœì—ì„œ ì¡°ì •
* **ê°€ëŠ”ëª¨ë°œ**: ê³¼ë„í•œ ë ˆì´ì–´ ë°©ì§€, Forward Weighted ì ìš©
* **êµµì€ëª¨ë°œ**: ë‚´ë¶€ í…ìŠ¤ì²˜ë§ìœ¼ë¡œ ë¬´ê²Œê° ë¶„ì‚°

**ê´€ë¦¬ë²•:**
* 2ì¼ì— 1íšŒ ê°€ë²¼ìš´ ìŠ¤íƒ€ì¼ë§ìœ¼ë¡œ ì¶©ë¶„
* 6ì£¼ í›„ ì¬ë°©ë¬¸ ê¶Œì¥
* ë³¼ë¥¨ ë¬´ìŠ¤ë‚˜ í…ìŠ¤ì²˜ ì—ì„¼ìŠ¤ ì†ŒëŸ‰ ì‚¬ìš©

âš¡ 20íŒŒë¼ë¯¸í„° ê³ ì† ì „ë¬¸ê°€ ê°€ì´ë“œ - 15ì´ˆ ì´ë‚´ ì‘ë‹µ ìµœì í™”"""

def is_valid_url(url: str) -> bool:
    """URL ìœ íš¨ì„± ê²€ì‚¬"""
    if not url or not isinstance(url, str):
        return False
    
    url = url.strip()
    if not url.startswith(('http://', 'https://')):
        return False
    
    if len(url) < 10 or len(url) > 2000:
        return False
    
    return True

# =============================================================================
# ëŒ€í™” ê´€ë¦¬ì
# =============================================================================

class ConversationManager:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.redis_available = redis_client is not None
        self.conversation_ttl = 86400 * 7
        self.memory_storage = {}
    
    def get_conversation_key(self, user_id: str, conversation_id: str) -> str:
        return f"hairgator:conversation:{user_id}:{conversation_id}"
    
    def create_conversation(self, user_id: str) -> str:
        return str(uuid.uuid4())
    
    def add_message(self, user_id: str, conversation_id: str, message: ChatMessage):
        conversation_key = self.get_conversation_key(user_id, conversation_id)
        
        if not message.timestamp:
            message.timestamp = datetime.now().isoformat()
        
        if self.redis_available:
            try:
                self.redis.lpush(conversation_key, message.model_dump_json())
                self.redis.expire(conversation_key, self.conversation_ttl)
            except:
                if conversation_key not in self.memory_storage:
                    self.memory_storage[conversation_key] = []
                self.memory_storage[conversation_key].insert(0, message.model_dump_json())
        else:
            if conversation_key not in self.memory_storage:
                self.memory_storage[conversation_key] = []
            self.memory_storage[conversation_key].insert(0, message.model_dump_json())
    
    def get_conversation_history(self, user_id: str, conversation_id: str, limit: int = 10) -> List[ChatMessage]:
        conversation_key = self.get_conversation_key(user_id, conversation_id)
        
        messages_json = []
        
        if self.redis_available:
            try:
                messages_json = self.redis.lrange(conversation_key, 0, limit - 1)
            except:
                messages_json = self.memory_storage.get(conversation_key, [])[:limit]
        else:
            messages_json = self.memory_storage.get(conversation_key, [])[:limit]
        
        messages = []
        for msg_json in reversed(messages_json):
            try:
                msg_data = json.loads(msg_json)
                messages.append(ChatMessage(**msg_data))
            except:
                continue
        
        return messages

# startup ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ë¥¼ lifespanìœ¼ë¡œ ìˆ˜ì •
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ ì‹¤í–‰
    global SELECTED_MODEL
    if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here' and openai:
        print("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ OpenAI ëª¨ë¸ í™•ì¸ ì¤‘...")
        SELECTED_MODEL = await get_available_openai_model()
    yield
    # ì¢…ë£Œ ì‹œ ì‹¤í–‰ (í•„ìš”ì‹œ)

# FastAPI ì•±ì— lifespan ì ìš©
app = FastAPI(
    title="í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ v8.0",
    description="15ì´ˆ ì´ë‚´ ì‘ë‹µì„ ìœ„í•œ 20íŒŒë¼ë¯¸í„° ê¸°ë°˜ í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ê³ ì† ë¶„ì„ ì‹œìŠ¤í…œ",
    version="8.0-fast-20param",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# ì˜ˆì™¸ í•¸ë“¤ëŸ¬
@app.exception_handler(422)
async def validation_exception_handler(request: Request, exc):
    print(f"âŒ 422 JSON ì˜¤ë¥˜ ë°œìƒ: {exc}")
    return JSONResponse(
        status_code=422,
        content={
            "detail": "JSON í˜•ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(exc)
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc):
    print(f"âŒ ì¼ë°˜ ì˜¤ë¥˜: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "detail": "ì„œë²„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(exc)
        }
    )

# ì •ì  íŒŒì¼ ì„œë¹™
try:
    app.mount("/static", StaticFiles(directory="static"), name="static")
    print("ğŸ“ Static íŒŒì¼ ì„œë¹™ í™œì„±í™”")
except Exception:
    os.makedirs("static", exist_ok=True)
    app.mount("/static", StaticFiles(directory="static"), name="static")
    print("ğŸ“ Static í´ë” ìƒì„± ë° ì„œë¹™ í™œì„±í™”")

# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
rag_db = HairgatorRAGDatabase()
professional_context = HairgatorProContextSystem()
conversation_manager = ConversationManager(redis_client)

# =============================================================================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.get("/")
async def root():
    return {
        "message": "í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ v8.0",
        "version": "8.0-fast-20param", 
        "features": [
            "20íŒŒë¼ë¯¸í„°ë¡œ ì¶•ì†Œí•˜ì—¬ 15ì´ˆ ì´ë‚´ ì‘ë‹µ",
            "OpenAI API íƒ€ì„ì•„ì›ƒ 15ì´ˆë¡œ ìµœì í™”",
            "ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ë¹ ë¥¸ ì²˜ë¦¬",
            "ìµœëŒ€ í† í° 1500ìœ¼ë¡œ ì¶•ì†Œ",
            "ë Œë” ë°°í¬ ìµœì í™”",
            "ì˜¤ë¥˜ ì—†ëŠ” ì™„ì „í•œ ì‹¤í–‰ ê°€ëŠ¥ ì½”ë“œ"
        ],
        "optimization": {
            "response_time": "15ì´ˆ ì´ë‚´",
            "parameter_count": 20,
            "max_tokens": 1500,
            "timeout": 15,
            "model_priority": ["gpt-4-turbo", "gpt-4", "gpt-3.5-turbo-16k", "gpt-3.5-turbo"]
        },
        "status": {
            "redis": "connected" if redis_available else "memory_mode",
            "openai": "configured" if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here' else "not_configured", 
            "claude": "disabled_for_speed",
            "rag_styles": len(rag_db.styles_data),
            "parameter_count": 20,
            "professional_context": True,
            "fast_optimized": True
        },
        "ready": True
    }

@app.post("/chat", response_model=ChatResponse)
async def fast_20param_chat(request: ChatRequest):
    """í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ê³ ì† 20íŒŒë¼ë¯¸í„° ë¶„ì„ - 15ì´ˆ ì´ë‚´"""
    try:
        user_id = str(request.user_id).strip()
        user_message = str(request.message).strip() if request.message else ""
        image_url = request.image_url
        
        # image_urlì´ "string"ì´ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° Noneìœ¼ë¡œ ì²˜ë¦¬
        if image_url in ["string", "", "null", "undefined"]:
            image_url = None
        
        print(f"âš¡ ê³ ì† ë¶„ì„ ì…ë ¥ê°’ í™•ì¸:")
        print(f"   user_message: '{user_message}'")
        print(f"   image_url: {image_url}")
        
        # ì´ë¯¸ì§€ë§Œ ìˆê³  ë©”ì‹œì§€ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ ì„¤ì •
        if not user_message and image_url:
            user_message = "ì´ë¯¸ì§€ í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„í•´ì¤˜"
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ë§Œ ì…ë ¥ - ê¸°ë³¸ ë©”ì‹œì§€ ì„¤ì •: {user_message}")
        
        # ì´ë¯¸ì§€ë„ ë©”ì‹œì§€ë„ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì—ëŸ¬
        if not user_message and not image_url:
            user_message = "í—¤ì–´ìŠ¤íƒ€ì¼ ë¶„ì„ ìš”ì²­"
            print(f"âš ï¸ ë¹ˆ ìš”ì²­ - ê¸°ë³¸ ë©”ì‹œì§€ ì„¤ì •: {user_message}")
        
        if not user_id:
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ì IDê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        conversation_id = request.conversation_id or conversation_manager.create_conversation(user_id)
        use_rag = request.use_rag
        
        print(f"âš¡ í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ - ì‚¬ìš©ì: {user_id}")
        if user_message:
            print(f"ğŸ“ ì§ˆë¬¸: {user_message[:50]}...")
        if image_url:
            print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: {image_url[:50]}...")
        
        # í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì‹œìŠ¤í…œì´ë¯€ë¡œ ëª¨ë“  ìš”ì²­ì„ 20íŒŒë¼ë¯¸í„° ë¶„ì„ìœ¼ë¡œ ì²˜ë¦¬
        print(f"âš¡ í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì‹œìŠ¤í…œ - 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì§„í–‰")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        user_msg = ChatMessage(
            role="user",
            content=user_message + (f" [ì´ë¯¸ì§€: {image_url}]" if image_url else ""),
            timestamp=datetime.now().isoformat()
        )
        conversation_manager.add_message(user_id, conversation_id, user_msg)
        
        # í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì‹œìŠ¤í…œ - ë°”ë¡œ 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì§„í–‰
        print("âš¡ í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ì‹œìŠ¤í…œ - 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì‹œì‘")
        
        # Claude ì´ë¯¸ì§€ ë¶„ì„ ìƒëµ (ì†ë„ ìµœì í™”)
        claude_analysis = None
        if image_url:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ì„ ìƒëµ (ê³ ì† ì²˜ë¦¬ë¥¼ ìœ„í•´)")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ê°„ì†Œí™”)
        rag_context = None
        if use_rag:
            print(f"ğŸ” RAG ê²€ìƒ‰ ì‹œì‘ (ê°„ì†Œí™”) - ì¿¼ë¦¬: '{user_message}'")
            similar_styles = rag_db.search_similar_styles(user_message)
            if similar_styles:
                rag_context = "ì°¸ê³  í—¤ì–´ê²Œì´í„° ë ˆì‹œí”¼:\n\n"
                for i, style in enumerate(similar_styles[:2]):  # ìµœëŒ€ 2ê°œë¡œ ì¶•ì†Œ
                    rag_context += f"[ë ˆí¼ëŸ°ìŠ¤ {i+1}]\n"
                    rag_context += f"ìŠ¤íƒ€ì¼ëª…: {style.get('introduction_kor', 'N/A')}\n"
                    rag_context += f"42í¬ë®¬ëŸ¬: {style.get('formula_42', 'N/A')}\n\n"
                
                print(f"âœ… RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ - {len(similar_styles)}ê°œ ìŠ¤íƒ€ì¼ ì°¸ì¡° (ê°„ì†Œí™”)")
            else:
                print("âš ï¸ RAG ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        else:
            print("ğŸ“š RAG ë¹„í™œì„±í™”")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ê°„ì†Œí™”)
        conversation_history = conversation_manager.get_conversation_history(
            user_id, conversation_id, limit=3  # 3ê°œë¡œ ì¶•ì†Œ
        )
        
        # í—¤ì–´ë””ìì´ë„ˆ ì „ìš© ê³ ì† 20íŒŒë¼ë¯¸í„° ì‘ë‹µ ìƒì„±
        print(f"âš¡ í—¤ì–´ë””ìì´ë„ˆ ì „ìš© 20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ ì‹¤í–‰")
        
        response_text = await generate_fast_20param_response(
            conversation_history,
            claude_analysis,
            rag_context
        )
        
        # ì‘ë‹µ ì €ì¥
        assistant_msg = ChatMessage(
            role="assistant",
            content=response_text,
            timestamp=datetime.now().isoformat()
        )
        conversation_manager.add_message(user_id, conversation_id, assistant_msg)
        
        print(f"âœ… í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ë¶„ì„ ì™„ë£Œ - ê¸¸ì´: {len(response_text)}")
        
        return ChatResponse(
            conversation_id=conversation_id,
            message=response_text,
            timestamp=assistant_msg.timestamp,
            message_type="fast_20_parameter_analysis",
            additional_data={
                "professional_analysis": True,
                "claude_analysis_used": False,  # ê³ ì† ì²˜ë¦¬ë¥¼ ìœ„í•´ ë¹„í™œì„±í™”
                "rag_context_used": bool(rag_context),
                "image_processed": bool(image_url),
                "parameter_count": 20,
                "analysis_version": "fast-v8.0-20param",
                "target_audience": "hair_professionals",
                "optimization": {
                    "response_time_target": "15ì´ˆ ì´ë‚´",
                    "max_tokens": 1500,
                    "timeout": 15,
                    "simplified_prompt": True
                }
            }
        )
        
    except ValueError as e:
        print(f"âŒ ì…ë ¥ ë°ì´í„° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=422, detail=f"ì…ë ¥ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        print(f"âŒ ê³ ì† ë¶„ì„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "version": "8.0-fast-20param",
        "timestamp": datetime.now().isoformat(),
        "optimization": {
            "response_time": "15ì´ˆ ì´ë‚´",
            "parameter_count": 20,
            "max_tokens": 1500,
            "timeout": 15,
            "fast_mode": True
        },
        "features": {
            "professional_context_detection": True,
            "image_url_support": True,
            "temp_upload_support": True,
            "20_parameter_fast_analysis": True,
            "optimized_for_render": True,
            "error_free": True
        },
        "services": {
            "redis": "connected" if redis_available else "memory_mode",
            "openai": "configured" if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here' else "not_configured",
            "claude": "disabled_for_speed"
        },
        "data": {
            "rag_styles": len(rag_db.styles_data),
            "total_parameters": 20,
            "professional_keywords": len(professional_context.professional_hair_keywords),
            "question_patterns": len(professional_context.professional_question_patterns)
        }
    }

@app.get("/test-20-parameters")
async def test_20_parameters():
    """20íŒŒë¼ë¯¸í„° ê³ ì† ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    return {
        "message": "v8.0 ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!",
        "version": "8.0-fast-20param",
        "optimization": {
            "response_time_target": "15ì´ˆ ì´ë‚´",
            "parameter_count": 20,
            "max_tokens": 1500,
            "api_timeout": 15,
            "simplified_processing": True
        },
        "professional_features": {
            "context_detection": True,
            "image_url_support": True,
            "expert_guidance": True,
            "technical_analysis": True,
            "fast_optimized": True
        },
        "render_deployment": {
            "api_endpoint": "https://hairgator-api.onrender.com/chat",
            "optimized_for_render": True,
            "fast_response": True,
            "production_ready": True
        },
        "note": "20íŒŒë¼ë¯¸í„°ë¡œ ì¶•ì†Œí•˜ì—¬ 15ì´ˆ ì´ë‚´ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ê³ ì† ìµœì í™” ë²„ì „ì…ë‹ˆë‹¤"
    }

# main ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    import uvicorn
    
    print("\nâš¡ í—¤ì–´ê²Œì´í„° ê³ ì† 20íŒŒë¼ë¯¸í„° ì‹œìŠ¤í…œ v8.0")
    print("ğŸ”§ v8.0 ê³ ì† ìµœì í™” ì™„ë£Œ:")
    print("   - 20íŒŒë¼ë¯¸í„°ë¡œ ì¶•ì†Œ")
    print("   - OpenAI API íƒ€ì„ì•„ì›ƒ: 15ì´ˆ")
    print("   - ìµœëŒ€ í† í°: 1500")
    print("   - ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸")
    print("   - Claude ì´ë¯¸ì§€ ë¶„ì„ ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)")
    print("   - RAG ê²€ìƒ‰ ê°„ì†Œí™”")
    
    # ë Œë” í™˜ê²½ ê°ì§€ ë° í¬íŠ¸ ì„¤ì •
    port = int(os.environ.get("PORT", 8000))
    host = "0.0.0.0"
    
    print(f"\nğŸš€ ë Œë” ë°°í¬ ê³ ì† ì„œë²„ ì‹œì‘:")
    print(f"   Host: {host}")
    print(f"   Port: {port}")
    print(f"   OpenAI: {'âœ… ì„¤ì •ë¨' if OPENAI_API_KEY and OPENAI_API_KEY != 'your_openai_key_here' else 'âŒ ë¯¸ì„¤ì •'}")
    print(f"   Claude: ë¹„í™œì„±í™” (ì†ë„ ìµœì í™”)")
    print(f"   Redis: {'ë©”ëª¨ë¦¬ëª¨ë“œ' if not redis_available else 'ì—°ê²°ë¨'}")
    print(f"   RAG ìŠ¤íƒ€ì¼: {len(rag_db.styles_data)}ê°œ")
    
    if not OPENAI_API_KEY or OPENAI_API_KEY == 'your_openai_key_here':
        print("\nâš ï¸ ê²½ê³ : OpenAI API í‚¤ê°€ ë Œë” í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("   Render Dashboard â†’ Environment â†’ OPENAI_API_KEY ì„¤ì • í•„ìš”")
    
    print(f"\nğŸ“‹ API ì—”ë“œí¬ì¸íŠ¸:")
    print(f"   â€¢ API ë¬¸ì„œ: https://your-app.onrender.com/docs")
    print(f"   â€¢ í—¬ìŠ¤ ì²´í¬: https://your-app.onrender.com/health")
    print(f"   â€¢ 20íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸: https://your-app.onrender.com/test-20-parameters")
    
    print(f"\nâš¡ ê³ ì† ìµœì í™” ì„¤ì •:")
    print(f"   â€¢ íŒŒë¼ë¯¸í„° ìˆ˜: 20ê°œ")
    print(f"   â€¢ ì‘ë‹µ ì‹œê°„: 15ì´ˆ ì´ë‚´")
    print(f"   â€¢ ìµœëŒ€ í† í°: 1500")
    print(f"   â€¢ API íƒ€ì„ì•„ì›ƒ: 15ì´ˆ")
    
    try:
        uvicorn.run(
            app, 
            host=host,
            port=port,
            log_level="info",
            access_log=True,
            workers=1,
            timeout_keep_alive=30,  # 30ì´ˆë¡œ ì„¤ì •
            limit_concurrency=5  # ë™ì‹œ ì—°ê²° ìˆ˜ ì œí•œ
        )
    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)